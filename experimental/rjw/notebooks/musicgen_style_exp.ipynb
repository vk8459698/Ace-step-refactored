{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7be031-e227-476b-a17b-6df1691f5abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8baa5482-e7a8-4ac4-ac9b-c08db7fa31b6",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac31131-269a-456c-a2d5-9d1f05dbe713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiocraft.models import musicgen\n",
    "from audiocraft.utils.notebook import display_audio\n",
    "import torch\n",
    "import torchaudio\n",
    "from audiocraft.models import MusicGen\n",
    "from audiocraft.data.audio import audio_write\n",
    "import glob, os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be05313d-1e0e-40d7-acdf-588497f6eb90",
   "metadata": {},
   "source": [
    "Well, according to https://huggingface.co/facebook/musicgen-style, the weights are Non-commercial:\n",
    "\"License: Code is released under MIT, model weights are released under CC-BY-NC 4.0.\"\n",
    "\n",
    "\n",
    "https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN_STYLE.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5b4b3-acb2-43d6-a59f-db0c4aabd3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MusicGen.get_pretrained('facebook/musicgen-style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f359408-5b21-443e-9a85-9b530fa7c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_generation_params(\n",
    "    duration=30, # generate 8 seconds, can go up to 30\n",
    "    use_sampling=True, \n",
    "    top_k=250,\n",
    "    cfg_coef=3., # Classifier Free Guidance coefficient \n",
    "    cfg_coef_beta=6,\n",
    "    # cfg_coef=3., # Classifier Free Guidance coefficient \n",
    "    # cfg_coef_beta=6., # double CFG is necessary for text-and-style conditioning\n",
    "    #                # Beta in the double CFG formula. between 1 and 9. When set to 1 it is equivalent to normal CFG. \n",
    "    #                # When we increase this parameter, the text condition is pushed. See the bottom of https://musicgenstyle.github.io/ \n",
    "    #                # to better understand the effects of the double CFG coefficients. \n",
    ")\n",
    "\n",
    "\n",
    "model.set_style_conditioner_params(\n",
    "    eval_q=1, # integer between 1 and 6\n",
    "              # eval_q is the level of quantization that passes\n",
    "              # through the conditioner. \n",
    "              # When low, the models adheres less to the \n",
    "              # audio conditioning\n",
    "    excerpt_length=4.5,\n",
    "    # excerpt_length=3., # the length in seconds that is taken by the model in the provided excerpt, can be                 \n",
    "                       # between 1.5 and 4.5 seconds but it has to be shortest to the length of the provided conditioning\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712fe1d9-9054-45dc-a813-59a90b7d9edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASH_AUDIO_PATH = \"/mnt/disks/audio-ai-research-speech-data/avi_ash_PROCESSED\"\n",
    "all_ash_paths = glob.glob(os.path.join(ASH_AUDIO_PATH, '*'))\n",
    "# ASH_TEST_AUDIO_PATH = os.path.join(ASH_AUDIO_PATH, \"15_EDOM__005.wav\") # This one is just too chaotic?\n",
    "ASH_TEST_AUDIO_PATH = os.path.join(ASH_AUDIO_PATH, \"12_Always On The Run__003.wav\")\n",
    "melody, sr = torchaudio.load(ASH_TEST_AUDIO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12663d5-e649-4291-a2ea-20ee2adeed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?model.generate_with_chroma\n",
    "START_TIME = 37\n",
    "END_TIME = 43\n",
    "start_index, end_index = START_TIME * sr, END_TIME * sr\n",
    "print(melody.shape)\n",
    "melody = melody[:, start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f76d8-ee04-4c93-acf4-414b94cc02a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = [\n",
    "    'Instrumental, lofi beats',\n",
    "    'Instrumental, classical, piano, instrumental, violin',\n",
    "    \"Instrumental, edm, synth, bass, euphoric, energetic\",\n",
    "    # 'Instrumental'\n",
    "    # \"hardcore metal riffs\",\n",
    "]\n",
    "wav = model.generate_with_chroma(\n",
    "    descriptions=descriptions, \n",
    "    melody_wavs=melody[None].expand(len(descriptions), -1, -1),\n",
    "    melody_sample_rate=sr,\n",
    "    progress = True,\n",
    "    return_tokens = False,\n",
    ")  # generates len(descriptions) samples.\n",
    "\n",
    "for idx, one_wav in enumerate(wav):\n",
    "    # Will save under {idx}.wav, with loudness normalization at -14 db LUFS.\n",
    "    filename = os.path.join('./musicgen_style', f'{idx}.wav')\n",
    "    audio_write(filename, one_wav.cpu(), model.sample_rate, strategy=\"loudness\", loudness_compressor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1ab508-8151-4a99-a377-b861ffd292b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "melody[None].expand(len(descriptions), -1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5ed8c-3e3b-4be0-b138-dcf4897dff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Audio(ASH_TEST_AUDIO_PATH))\n",
    "display(Audio(data=melody, rate=sr))\n",
    "for _audio_fp, _description in zip(glob.glob('./musicgen_style/*'), np.array(descriptions)[::-1]):\n",
    "    print('===== ===== ===== ===== =====')\n",
    "    print(_description)\n",
    "    print(_audio_fp)\n",
    "    display(Audio(_audio_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e313ff06-a082-423c-87ba-5c0f2e82b3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7033cd-17d1-4b32-9d0d-8574e4af526f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchpy310",
   "language": "python",
   "name": "torchpy310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
