{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d544b9e-1ef1-4bcf-afdf-3b714d9bff2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "644e1cfd-fb5d-4c62-9b09-e3fd61b180a7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1104cf-d72c-4b18-92f1-df7474e807c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import copy\n",
    "import tqdm\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import Audio, Markdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 3)\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "# import itables\n",
    "# itables.init_notebook_mode()\n",
    "# from sklearn.model_selection import ParameterGrid\n",
    "# import librosa\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f1569-2faf-4459-975e-5e3fb2874762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Output, GridspecLayout, HBox, VBox, Text, HTML\n",
    "# from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a256dfe-98b0-4f27-8ec9-0b8ae6fc25f9",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a97a4-c9ad-47bc-a310-7f3ea1d81719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_name='exp_01' # This experiment shows to use 'heun', and high omega and guidance\n",
    "# experiment_name='exp_02' # too drastic of ref_audio_strength\n",
    "experiment_name='exp_03' # too drastic of ref_audio_strength\n",
    "audio_outputs_path = f'/mnt/disks/ace_step_generation/{experiment_name}'\n",
    "\n",
    "grid_search_input_dataframe_filepath = os.path.join(audio_outputs_path, 'grid_search_input_data.csv')\n",
    "grid_dataframe = pd.read_csv(grid_search_input_dataframe_filepath)\n",
    "\n",
    "grid_search_output_dataframe_filepath = os.path.join(audio_outputs_path, 'grid_search_output_data.csv')\n",
    "results_dataframe = pd.read_csv(grid_search_output_dataframe_filepath)\n",
    "\n",
    "a2a_results_df = results_dataframe[\n",
    "    ~results_dataframe['ref_audio_input'].isna()\n",
    "]\n",
    "print(f'Originally {a2a_results_df.shape[0]} audio2audio results have been generated...')\n",
    "t2a_results_df = results_dataframe[\n",
    "    results_dataframe['ref_audio_input'].isna()\n",
    "]\n",
    "print(f'Originally {t2a_results_df.shape[0]} text2audio results have been generated...')\n",
    "\n",
    "BASE_AUDIO_DIR = \"~/soundverse/ACE-step-lowvram/experimental/rjw/notebooks/outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed182cf2-c488-43f4-a61d-f45079dce9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2a_results_df = a2a_results_df.sort_values(\n",
    "#     by=[\n",
    "#         'prompt','infer_step', 'scheduler_type','omega_scale',\n",
    "#         'use_erg','guidance_scale', 'guidance_interval',  'ref_audio_strength'\n",
    "#    ],\n",
    "#     ascending=[\n",
    "#         False, False, True, True,\n",
    "#         True, False, True, True\n",
    "#     ]\n",
    "# ).reset_index(drop=True)\n",
    "original_file = a2a_results_df.iloc[0]['ref_audio_input']\n",
    "original_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea7aa7-0c36-4fb0-a1af-fb15a8c398c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2a_results_df[\n",
    "#     (\n",
    "#         (a2a_results_df['omega_scale'] == 30) &\n",
    "#         (a2a_results_df['ref_audio_strength'] == 0.1) &\n",
    "#         (a2a_results_df['prompt'] == 'edm, synth, bass, euphoric and energetic')\n",
    "#     )\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2a36e-6c66-42a5-aba4-292f12d98f98",
   "metadata": {},
   "source": [
    "# Examination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7639a242-84f0-4091-bb1c-f97efc7b1313",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466dc17b-219f-485f-beda-8b5578e4c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_difference(\n",
    "    previous_params, \n",
    "    current_params,\n",
    "    ignore_columns = ['timecosts', 'retake_seeds', 'audio_path']\n",
    "):\n",
    "    if isinstance(previous_params, pd.core.series.Series):\n",
    "        previous_params = previous_params.to_dict()\n",
    "    if isinstance(current_params, pd.core.series.Series):\n",
    "        current_params = current_params.to_dict()\n",
    "\n",
    "    parameter_differences = {}\n",
    "    \n",
    "    for _key_current, _value_current in current_params.items():\n",
    "        if _key_current in ignore_columns:\n",
    "            continue\n",
    "        _value_previous = previous_params.get(_key_current)\n",
    "        \n",
    "        if _value_previous != _value_current:\n",
    "            parameter_differences[_key_current] = {\n",
    "                'previous': _value_previous,\n",
    "                'current': _value_current\n",
    "            }\n",
    "    return parameter_differences\n",
    "\n",
    "def compute_same(\n",
    "    previous_params, \n",
    "    current_params,\n",
    "    similar_allow_list=[\n",
    "        'prompt',\n",
    "        'lyrics',\n",
    "        'ref_audio_input',\n",
    "        'guidance_scale',\n",
    "        'guidance_interval',\n",
    "        'guidance_interval_decay',\n",
    "        'scheduler_type',\n",
    "        'infer_step',\n",
    "        'ref_audio_strength',\n",
    "        'use_erg',\n",
    "        'omega_scale',\n",
    "    ]\n",
    "):\n",
    "    if isinstance(previous_params, pd.core.series.Series):\n",
    "        previous_params = previous_params.to_dict()\n",
    "    if isinstance(current_params, pd.core.series.Series):\n",
    "        current_params = current_params.to_dict()\n",
    "\n",
    "    parameter_similarities = {}\n",
    "    \n",
    "    for _key_current, _value_current in current_params.items():\n",
    "        if _key_current not in similar_allow_list:\n",
    "            continue\n",
    "\n",
    "        _value_previous = previous_params.get(_key_current)\n",
    "        \n",
    "        if _value_previous == _value_current:\n",
    "            parameter_similarities[_key_current] = {\n",
    "                'value': _value_previous\n",
    "            }\n",
    "    return parameter_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080271c4-15f6-40fb-b6aa-e5f407db6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_same_vs_different(\n",
    "    different_df, same_df, audio_path_0, audio_path_1, index_0, index_1\n",
    "):\n",
    "   \n",
    "    grid = GridspecLayout(1, 2)\n",
    "    out = Output()\n",
    "    # Display Audios\n",
    "    with out:\n",
    "        # display(Markdown(f'# Index: {index_0}'))\n",
    "        display(HTML(f'# Index: {index_0}'))\n",
    "        display(Audio(audio_path_0))\n",
    "        # display(Markdown(f'# Index: {index_1}'))\n",
    "        display(HTML(f'# Index: {index_1}'))\n",
    "        display(Audio(audio_path_1))\n",
    "\n",
    "\n",
    "\n",
    "    grid[0, 0] = out\n",
    "    \n",
    "    # Display DataFrames\n",
    "    out = Output()\n",
    "    with out:\n",
    "        # display(Markdown(f'# Different Properties'))\n",
    "        display(HTML(f'# Different Properties'))\n",
    "        display(different_df)\n",
    "        # display(Markdown(f'# Same Properties'))\n",
    "        display(HTML(f'# Same Properties'))\n",
    "        display(same_df)\n",
    "        \n",
    "    grid[0, 1] = out\n",
    "    display(grid)\n",
    "    # return grid   \n",
    "\n",
    "\n",
    "def display_same_vs_different_v2(\n",
    "    different_df, same_df, audio_path_0, audio_path_1, index_0, index_1\n",
    "):\n",
    "    display(Markdown('## ===== ===== ===== ===== ===== ===== ===== ====='))\n",
    "    \n",
    "    display(Markdown(f'# Index: {index_0}'))\n",
    "    display(Audio(audio_path_0))\n",
    "    display(Markdown(f'# Index: {index_1}'))\n",
    "    display(Audio(audio_path_1))\n",
    "\n",
    "    \n",
    "    # Display DataFrames\n",
    "\n",
    "    display(Markdown(f'# Different Properties'))\n",
    "    display(different_df)\n",
    "    display(Markdown(f'# Same Properties'))\n",
    "    display(same_df)\n",
    "\n",
    "    display(Markdown('## ===== ===== ===== ===== ===== ===== ===== ====='))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6223c129-480f-4534-897b-8ac4352015d3",
   "metadata": {},
   "source": [
    "## Examine Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92afbfa1-6a6b-46df-8bbb-42315745b7bb",
   "metadata": {},
   "source": [
    "#### Create index Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c966c2-b6f4-4ae1-9240-f098c7b72f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique prompts that have been generated:')\n",
    "display(a2a_results_df['prompt'].unique().tolist())\n",
    "print('\\nn records per prompt:')\n",
    "display(a2a_results_df.groupby(['prompt']).count().reset_index(drop=False)[['prompt','format']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8070282f-ceb1-427e-be0c-471e69271145",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Filtering Using text2audio Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8033216-57b6-4d7f-9360-7f176ff54ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = t2a_results_df[\n",
    "#     (\n",
    "#         # (a2a_results_df['omega_scale'] == 30) &\n",
    "#         # (a2a_results_df['ref_audio_strength'] == 0.1) &\n",
    "#         # (a2a_results_df['guidance_interval'] == 1.0) & # makes huge difference too!\n",
    "#         # (a2a_results_df['prompt'] == 'edm, synth, bass, euphoric and energetic') &\n",
    "#         (t2a_results_df['prompt'] == 'lofi beats') &\n",
    "#         # (a2a_results_df['scheduler_type'].isin(['heun', 'pingpong']))\n",
    "#         # ===== use_ergTrue gives more variation which is nice, but maybe shortcuts using CFG???\n",
    "#         (t2a_results_df['use_erg'] == False) & \n",
    "#         (t2a_results_df['scheduler_type'].isin(['heun']))\n",
    "        \n",
    "        \n",
    "#     )\n",
    "# ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c116a80-6d5e-4b1a-9eb4-e3f9bc9b62cb",
   "metadata": {},
   "source": [
    "### Filtering Using audio2audio Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb2159-e4b3-4e0d-83ce-eb1c8f576162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a2a_results_df.astype('category').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9946ee97-b205-4da3-9e60-b28162703e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = a2a_results_df[\n",
    "    (\n",
    "        # (a2a_results_df['omega_scale'] == 30) &\n",
    "        # (a2a_results_df['ref_audio_strength'].isin([.15])) &\n",
    "        (a2a_results_df['ref_audio_strength'].isin([0.1, 1.5])) &\n",
    "        (a2a_results_df['guidance_scale'] == 30.0) & # makes huge difference too!\n",
    "        (a2a_results_df['guidance_interval'] == 0.9) & # makes huge difference too!\n",
    "        # (a2a_results_df['guidance_interval'] == 1.0) & # makes huge difference too!\n",
    "        # (a2a_results_df['prompt'] == 'edm, synth, bass, euphoric and energetic')  &\n",
    "        # (a2a_results_df['prompt'] == 'lofi beats') &\n",
    "        # (a2a_results_df['scheduler_type'].isin(['heun', 'pingpong']))\n",
    "        # ===== use_ergTrue gives more variation which is nice, but maybe shortcuts using CFG???\n",
    "        (a2a_results_df['use_erg'] == False) & \n",
    "        (a2a_results_df['scheduler_type'].isin(['heun']))\n",
    "        \n",
    "        \n",
    "    )\n",
    "].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# filtered_df.head(5)\n",
    "print(f'filtered to {filtered_df.shape[0]} results...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957fe3fa-23f9-493b-b8f8-c5a6f6de140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('# Original Reference Audio'))\n",
    "display(Audio(original_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52f81e3-3539-4f02-8302-a4752ff3ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = a2a_results_df.index.to_list()\n",
    "indices = filtered_df.index.to_list()\n",
    "\n",
    "index_pairs = list(combinations(indices, 2))\n",
    "if len(index_pairs) == 0:\n",
    "    index_pairs = [[0, 0]]\n",
    "    \n",
    "N_PAIRS = 7\n",
    "print(f\"For {len(indices)} remaining tracks post-filtering,\")\n",
    "print(f\"there are {len(index_pairs)} possible pairs...\")\n",
    "print(f\"Limiting to {N_PAIRS} examples.\")\n",
    "\n",
    "# for _i, (_index_0, _index_1) in enumerate(index_pairs[:N_PAIRS]):\n",
    "for _i, (_index_0, _index_1) in enumerate(index_pairs[-N_PAIRS:]):\n",
    "    \n",
    "    previous_params = filtered_df.iloc[_index_0].replace({float('nan'): None})   \n",
    "    current_params = filtered_df.iloc[_index_1].replace({float('nan'): None})   \n",
    "\n",
    "    \n",
    "    param_differences = compute_difference(\n",
    "        previous_params=previous_params, \n",
    "        current_params=current_params\n",
    "    )\n",
    "    params_same = compute_same(\n",
    "        previous_params=previous_params, \n",
    "        current_params=current_params\n",
    "    )\n",
    "    \n",
    "    display_same_vs_different_v2(\n",
    "        different_df=pd.DataFrame(param_differences).T,\n",
    "        same_df=pd.DataFrame(params_same).T,\n",
    "        audio_path_0=previous_params['audio_path'],\n",
    "        audio_path_1=current_params['audio_path'], \n",
    "        index_0=_index_0, index_1=_index_1\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2215c2-6ba5-4bf0-afe2-847d07e9f0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709ef86e-519d-4874-ba65-4a08f516fb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9260a25-faf5-43e6-a0d0-d3827cb06d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f510ed08-fc42-42a3-ad54-881b720c884f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ace_step",
   "language": "python",
   "name": "ace_step"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
