{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678b20a7-4f8c-4a40-8ab3-0f16236514b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59106554-0b93-49c9-a2a9-022f8cb05039",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8a20e9-3483-4201-973b-fc107213a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import copy\n",
    "import tqdm\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import itables\n",
    "# itables.init_notebook_mode()\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ff485-27fa-4e0b-841a-df6c4ca2dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from acestep.ui.components import create_main_demo_ui\n",
    "from acestep.pipeline_ace_step import ACEStepPipeline\n",
    "# from acestep.data_sampler import DataSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1c1fac-12b8-4176-90ff-2ac917ca649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !ls outputs\n",
    "# display(Audio(ASH_TEST_AUDIO_PATH))\n",
    "# Audio(output_paths)#, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02371db-1a29-4c90-9ccb-161fa539859f",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224364ee-0d26-4792-bd44-cef92a5a590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path=\"~/.cache/ace-step/checkpoints/models--ACE-Step--ACE-Step-v1-3.5B/\"\n",
    "# checkpoint_path=\"f\"\n",
    "\n",
    "# LORA_DIR='/home/rileywilliams/soundverse/ACE-step-lowvram/models/exp/ace_step_lora_rjwpersonal/'\n",
    "# LORA_PATH=os.path.join(LORA_DIR, \"epoch=56-step=6000_lora\")\n",
    "# LORA_PATH='none'\n",
    "# LORA_PATH=\"/home/rileywilliams/soundverse/ACE-step-lowvram/ace_step_lora/shoujobyou\"\n",
    "BF16=False\n",
    "TORCH_COMPILE=True\n",
    "CPU_OFFLOAD=True\n",
    "OVERLAPPED_DECODE=True # maybe try false?\n",
    "\n",
    "try:\n",
    "    del model_demo\n",
    "except:\n",
    "    pass\n",
    "model_demo = ACEStepPipeline(\n",
    "    # checkpoint_dir=checkpoint_path,\n",
    "    dtype=\"bfloat16\" if BF16 else \"float32\",\n",
    "    torch_compile=TORCH_COMPILE,\n",
    "    cpu_offload=CPU_OFFLOAD,\n",
    "    overlapped_decode=OVERLAPPED_DECODE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90944002-a8d4-4c37-a4b6-cccb1d5a37f0",
   "metadata": {},
   "source": [
    "Entropy Rectifying Guidance (ERG) for tag-transformer/lyrics/diffusion model. It will multiple a temperature to the attention to make a weaker tag condition and make better diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46689719-201c-4733-ab15-3a60f70026e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 / math.sqrt(64)\n",
    "# # model_demo.ace_step_transformer.unload_lora()\n",
    "# wget https://huggingface.co/woctordho/ACE-Step-v1-LoRA-collection/resolve/main/ace_step_v1_lora_shoujobyou.safetensors?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13a7e5-abff-4942-996b-a2c1963d4a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcloud compute scp --recurse --compress --zone \"us-west1-b\" --project \"theapp-388314\" \\\n",
    "# \"/Users/rileywilliams/Music/Logic/SoundVerse/avi_ash_PROCESSED\" \\\n",
    "# rileywilliams@dev-gpu-rjw:\"/mnt/disks/audio-ai-research-speech-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdb5d1c-5da3-4ab5-af31-e1cd67b9edff",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bb8101-838c-456b-8fb0-97baed93ddec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### With LoRa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7a199f-1121-4847-8caa-fff6997878b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LYRICS='[Instrumental]'\n",
    "# LYRICS=''\n",
    "# LORA_WEIGHT=1.0\n",
    "LORA_WEIGHT=1 / math.sqrt(64) # where 64 is the rank of the LoRa\n",
    "# LORA_WEIGHT=1 / 64\n",
    "# LORA_WEIGHT=0.05 # 1.0\n",
    "LORA_TRIGGER_WORD='4abe0dc877704be489c89dc07927921f'\n",
    "PROMPT=f\"{LORA_TRIGGER_WORD}. calm electronic melodic house at sunset\"\n",
    "# PROMPT=\"calm electronic melodic house at sunset\"\n",
    "# PROMPT=f'{LORA_TRIGGER_WORD}'\n",
    "# PROMPT=''\n",
    "MANUAL_SEEDS = 42\n",
    "AUDIO_DURATION = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104e722-da2a-4ef6-910a-f9c997fdf394",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_paths, input_params_json = model_demo(\n",
    "    # format: str = \"wav\",\n",
    "        audio_duration=AUDIO_DURATION, #: float = 60.0,\n",
    "        prompt=PROMPT,\n",
    "        lyrics=LYRICS, #     lyrics: str = None,\n",
    "    #     infer_step: int = 60,\n",
    "    #     guidance_scale: float = 15.0,\n",
    "    #     scheduler_type: str = \"euler\",\n",
    "        cfg_type = \"apg\",\n",
    "        omega_scale = 20.0, #(this is \"granularity\" in the GUI, defaults to 10)\n",
    "    #     omega_scale: int = 10.0, (this is \"granularity\" in the GUI)\n",
    "        manual_seeds=MANUAL_SEEDS, # None,\n",
    "        guidance_interval=1.0, #     guidance_interval: float = 0.5,\n",
    "    #     guidance_interval_decay: float = 0.0,\n",
    "    #     min_guidance_scale: float = 3.0,\n",
    "    #     use_erg_tag: bool = True,\n",
    "    #     use_erg_lyric: bool = True,\n",
    "    #     use_erg_diffusion: bool = True,\n",
    "    #     oss_steps: str = None,\n",
    "        guidance_scale_text = 5.0,\n",
    "        guidance_scale_lyric = 1.5,\n",
    "    #     guidance_scale_text: float = 0.0, # 5.0\n",
    "    #     guidance_scale_lyric: float = 0.0, # 1.5\n",
    "    #     audio2audio_enable: bool = False,\n",
    "    #     ref_audio_strength: float = 0.5,\n",
    "    #     ref_audio_input: str = None,\n",
    "        # lora_name_or_path='none',\n",
    "        lora_name_or_path=LORA_PATH, # \"none\n",
    "        lora_weight=LORA_WEIGHT,\n",
    "        # retake_seeds: list = None,\n",
    "        # retake_variance: float = 0.5,\n",
    "        # task: str = \"text2music\",\n",
    "        # src_audio_path: str = None,\n",
    "        # edit_target_prompt: str = None,\n",
    "        # edit_target_lyrics: str = None,\n",
    "        # edit_n_min: float = 0.0,\n",
    "        # edit_n_max: float = 1.0,\n",
    "        # edit_n_avg: int = 1,\n",
    "        # save_path: str = None,\n",
    "        # batch_size: int = 1,\n",
    "        # debug: bool = False,\n",
    ")\n",
    "# data_sampler = DataSampler()\n",
    "\n",
    "# demo = create_main_demo_ui(\n",
    "#     text2music_process_func=model_demo.__call__,\n",
    "#     sample_data_func=data_sampler.sample,\n",
    "#     load_data_func=data_sampler.load_json,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab39f62-5df2-4f3e-8dd4-0f5d03676ba4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5df95c-f43f-4dbc-9123-3caa6db22c46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Riley's LoRa, with lyrics as empty string\n",
    "# 'calm electronic melodic house at sunset',\n",
    "# './outputs/output_20250617003852_0.wav'\n",
    "\n",
    "# Using Riley's LoRa, with lyrics='[Instrumental]'\n",
    "# 'calm electronic melodic house at sunset',\n",
    "# './outputs/output_20250617005807_0.wav'\n",
    "\n",
    "# Using Riley's LoRa, with lyrics='[Instrumental]', and f\"{LORA_TRIGGER_WORD} calm electronic melodic house at sunset\"\n",
    "# 'calm electronic melodic house at sunset',\n",
    "# './outputs/output_20250617010151_0.wav'\n",
    "\n",
    "# Using Riley's LoRa, with lyrics='[Instrumental]', and\n",
    "# PROMPT='4abe0dc877704be489c89dc07927921f,Dance music, ambient music,In the genre of electronic and dance and ambient,118 bpm'\n",
    "# './outputs/output_20250617011301_0.wav'\n",
    "\n",
    "# Using Riley's LoRa, with lyrics='[Instrumental]', and\n",
    "# PROMPT='4abe0dc877704be489c89dc07927921f'\n",
    "# './outputs/output_20250617011503_0.wav'\n",
    "\n",
    "# Using Riley's LoRa, with lyrics='[Instrumental]', and\n",
    "# PROMPT=''\n",
    "# './outputs/output_20250617012344_0.wav'\n",
    "\n",
    "# Using Riley's LoRa, with lyrics='', and PROMPT=''\n",
    "# './outputs/output_20250617012759_0.wav'\n",
    "\n",
    "# ===== ===== ===== ===== =====\n",
    "\n",
    "# Using WITHOUT Riley's LoRa\n",
    "# 'calm electronic melodic house at sunset',\n",
    "# './outputs/output_20250617005206_0.wav'\n",
    "# with lyrics as empty string, I get chinese singing :/\n",
    "\n",
    "# Using WITHOUT Riley's LoRa, but with lyrics='[Instrumental]' (now it works fine!)\n",
    "# 'calm electronic melodic house at sunset',\n",
    "# './outputs/output_20250617005541_0.wav'\n",
    "# with lyrics as empty string, I get chinese singing :/\n",
    "\n",
    "\n",
    "# , input_params_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb51daf3-3294-4710-8e19-41695218764f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27943043-a6d1-46ef-9770-d921e5bff980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Riley's LoRa, with lyrics='', and PROMPT=''\n",
    "# './outputs/output_20250617012759_0.wav'\n",
    "# Most recent (riley's lora): './outputs/output_20250617155406_0.wav'\n",
    "output_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ee5ef-f930-441b-b425-73816ef6bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rileys')\n",
    "display(Audio('./outputs/output_20250617155406_0.wav', autoplay=False))\n",
    "print('base')\n",
    "display(Audio('./outputs/output_20250617160348_0.wav', autoplay=False))\n",
    "print('bad')\n",
    "Audio(output_paths, autoplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fc1d13-5548-4426-958e-d3d1c5a6caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LYRICS='[Instrumental]'\n",
    "# # LYRICS=''\n",
    "# LORA_WEIGHT=0.2 # 1.0\n",
    "# LORA_TRIGGER_WORD='4abe0dc877704be489c89dc07927921f'\n",
    "# PROMPT=f\"{LORA_TRIGGER_WORD} calm electronic melodic house at sunset\"\n",
    "# './outputs/output_20250617013545_0.wav'\n",
    "\n",
    "# LYRICS='[Instrumental]'\n",
    "# # LYRICS=''\n",
    "# LORA_WEIGHT=0.05 # 1.0\n",
    "# LORA_TRIGGER_WORD='4abe0dc877704be489c89dc07927921f'\n",
    "# PROMPT=f\"{LORA_TRIGGER_WORD} calm electronic melodic house at sunset\"\n",
    "# './outputs/output_20250617014204_0.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9326be-4598-41c5-afaf-befb731e217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_demo.__call__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f656d0-5fe4-47e8-8ea3-b304314b5bc8",
   "metadata": {},
   "source": [
    "### Using Audio2Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d2919-cb81-42e5-861b-6aef9b99b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASH_AUDIO_PATH = \"/mnt/disks/audio-ai-research-speech-data/avi_ash_PROCESSED\"\n",
    "all_ash_paths = glob.glob(os.path.join(ASH_AUDIO_PATH, '*'))\n",
    "# ASH_TEST_AUDIO_PATH = os.path.join(ASH_AUDIO_PATH, \"15_EDOM__005.wav\") # This one is just too chaotic?\n",
    "ASH_TEST_AUDIO_PATH = os.path.join(ASH_AUDIO_PATH, \"12_Always On The Run__003.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf9ac8c-df81-4f6b-a0af-fab291aabd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_index = -36\n",
    "# ASH_TEST_AUDIO_PATH = all_ash_paths[file_index]\n",
    "# display(Audio(ASH_TEST_AUDIO_PATH, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52f29d-6955-4627-bb9f-44d195c87e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_params_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f1a6a-efe4-4055-8f7b-7894a4000f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "MANUAL_SEEDS=296772417648513\n",
    "LYRICS='[Instrumental]'\n",
    "PROMPT='lofi beats'\n",
    "# PROMPT='classical, piano, instrumental'\n",
    "# PROMPT='soft jazz, light piano'\n",
    "# PROMPT=\"edm, synth, bass, euphoric, energetic\"\n",
    "# PROMPT=\"\"\n",
    "# PROMPT=\"hardcore metal riffs\"\n",
    "AUDIO_DURATION = 43\n",
    "output_paths, input_params_json = model_demo(\n",
    "    # format: str = \"wav\",\n",
    "        audio_duration=AUDIO_DURATION, #: float = 60.0,\n",
    "        prompt=PROMPT,\n",
    "        lyrics=LYRICS, #     lyrics: str = None,\n",
    "        infer_step = 100,\n",
    "\n",
    "        # guidance_scale = 15.0, # When guidance_scale_lyric > 1 and guidance_scale_text > 1, the guidance scale will not be applied.\n",
    "        scheduler_type = \"heun\",\n",
    "        # scheduler_type = \"pingpong\",\n",
    "        # scheduler_type = \"euler\", # \"euler\" is recommended, heun will take more time\n",
    "        cfg_type = \"apg\",\n",
    "        # cfg_type = \"cfg\",\n",
    "        omega_scale = 10.0, # (this is \"granularity\" in the GUI, defaults to 10)\n",
    "        # omega_scale: int = 10.0,\n",
    "        manual_seeds=MANUAL_SEEDS, # None,\n",
    "        guidance_scale=15,\n",
    "        guidance_interval=0.5,\n",
    "        # guidance_interval=1.0,\n",
    "        # guidance_interval: float = 1.0,\n",
    "        guidance_interval_decay = 0.0,\n",
    "        min_guidance_scale = 3.0,\n",
    "    \n",
    "        # use_erg_tag=False,\n",
    "        # use_erg_lyric=False,\n",
    "        # use_erg_diffusion=False,\n",
    "        use_erg_tag=True,\n",
    "        use_erg_lyric=True,\n",
    "        use_erg_diffusion=True,\n",
    "    \n",
    "    #     use_erg_tag: bool = True,\n",
    "    #     use_erg_lyric: bool = True,\n",
    "    #     use_erg_diffusion: bool = True,\n",
    "    #     oss_steps: str = None,\n",
    "    #     guidance_scale_text: float = 0.0,\n",
    "    #     guidance_scale_lyric: float = 0.0,\n",
    "        # guidance_scale_text = 7,\n",
    "        # guidance_scale_lyric = 2,\n",
    "    \n",
    "        # audio2audio_enable = True,\n",
    "        # ref_audio_strength = 0.10, # 0.18 was good on Gradio site...\n",
    "        # ref_audio_input = ASH_TEST_AUDIO_PATH,\n",
    ")\n",
    "print(output_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9267fa2-dd0c-416a-99a5-305b89f81f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls outputs\n",
    "print(PROMPT)\n",
    "# display(Audio(ASH_TEST_AUDIO_PATH))\n",
    "Audio(output_paths)#, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5033ebe8-2ed5-46d1-8b13-1c4f50f90376",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_params_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb623982-7653-4e0e-9d73-e5ff01ab5700",
   "metadata": {},
   "source": [
    "# Set up Hyperparam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660592af-e82c-4ec3-80fa-0f5aea2771be",
   "metadata": {},
   "source": [
    "## Generate Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bffd48-36fa-458d-b464-f75d795cd14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_params(target, recorded):\n",
    "    merged_params = copy.copy(recorded)\n",
    "    for _key, _value in target.items():\n",
    "        merged_params[_key] = _value\n",
    "    return merged_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ee39c-2b9a-4a25-91cf-45ea8c0e264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MANUAL_SEEDS=296772417648513\n",
    "AUDIO_DURATION = 43\n",
    "\n",
    "prompts_list = [\n",
    "    'lofi beats',\n",
    "    # 'soft jazz with light piano',\n",
    "    \"edm, synth, bass, euphoric\"\n",
    "]\n",
    "\n",
    "lyrics_list = [\n",
    "    '[Instrumental]'\n",
    "]\n",
    "\n",
    "track_list = [\n",
    "    ASH_TEST_AUDIO_PATH, None\n",
    "]\n",
    "\n",
    "param_grid_dict = {\n",
    "    \"audio_duration\" : [AUDIO_DURATION],\n",
    "    'prompt': prompts_list,\n",
    "    'lyrics': lyrics_list,\n",
    "    'ref_audio_input': track_list,\n",
    "    'guidance_scale': [30, 15], # Max guidance before decay (30 is highest)\n",
    "    'scheduler_type': ['heun', 'pingpong'],\n",
    "    'infer_step': [70], \n",
    "    # 'ref_audio_strength': np.arange(.1, .36, .1),\n",
    "    'ref_audio_strength':[.075, .1, .15],\n",
    "    'use_erg': [False, True], # I think if erg is used, then cfg/apg isn't used?\n",
    "    'manual_seeds': [MANUAL_SEEDS],\n",
    "    'omega_scale': [100, 10], # Granularity, 100 is max\n",
    "    'guidance_interval': [0.5, 0.9, 1.0],\n",
    "    \"guidance_interval_decay\": [0.0, 0.25, 0.75],\n",
    "    \"min_guidance_scale\": [3],\n",
    "}\n",
    "\n",
    "param_grid = ParameterGrid(param_grid_dict)\n",
    "len(param_grid)\n",
    "# param_grid_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a9020d-086d-42d6-9f90-543af1302b41",
   "metadata": {},
   "source": [
    "### Prepare param grid dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b955c60c-4ac4-4cce-8064-0fbb1c02dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name='exp_03'\n",
    "audio_outputs_path = f'/mnt/disks/ace_step_generation/{experiment_name}'\n",
    "os.makedirs(audio_outputs_path, exist_ok=True)\n",
    "\n",
    "grid_search_input_dataframe_filepath = os.path.join(audio_outputs_path, 'grid_search_input_data.csv')\n",
    "\n",
    "# if starting from scratch\n",
    "grid_dataframe = pd.DataFrame(param_grid)\n",
    "grid_dataframe['complete'] = False\n",
    "grid_dataframe['audio_outputs_path'] = audio_outputs_path\n",
    "# If restarting from file\n",
    "# grid_dataframe = pd.read_csv(grid_search_input_dataframe_filepath)\n",
    "\n",
    "\n",
    "grid_dataframe.to_csv(\n",
    "    path_or_buf=grid_search_input_dataframe_filepath,\n",
    "    mode='w',\n",
    "    index=False\n",
    ")\n",
    "grid_search_output_dataframe_filepath = os.path.join(audio_outputs_path, 'grid_search_output_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7793bda3-523b-45f0-9eb1-830c9f20330e",
   "metadata": {},
   "source": [
    "#### Filter audio strength options for non audio2audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c0adf7-8256-4c06-a729-e172aea913e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'starting with {grid_dataframe.shape[0]} variations')\n",
    "default_ref_audio = 0.1\n",
    "\n",
    "repeat_condition = grid_dataframe['ref_audio_input'].isna()\n",
    "\n",
    "grid_dataframe.loc[\n",
    "    repeat_condition,\n",
    "    'ref_audio_strength'\n",
    "]= default_ref_audio\n",
    "grid_dataframe = grid_dataframe.drop_duplicates().reset_index(drop=True)\n",
    "print(f'ending with {grid_dataframe.shape[0]} variations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2895b79a-5e51-47c2-9047-7e09ac20ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_dataframe = grid_dataframe.sort_values(\n",
    "#     by=['ref_audio_input', 'prompt','infer_step', 'guidance_scale', 'use_erg', 'scheduler_type'], \n",
    "#     ascending=[True, True, False, False, True, True]\n",
    "# )\n",
    "# grid_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbdd0d-f98c-46cd-af04-a50f65951846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song(params):\n",
    "    output_paths, input_params_json = model_demo(\n",
    "        audio_duration=params['audio_duration'],\n",
    "        prompt=params['prompt'],\n",
    "        lyrics=params['lyrics'],\n",
    "        infer_step = params['infer_step'],\n",
    "        scheduler_type = params['scheduler_type'],\n",
    "        manual_seeds=params['manual_seeds'],\n",
    "        guidance_interval=params['guidance_interval'],\n",
    "        guidance_scale=params['guidance_scale'],\n",
    "        guidance_interval_decay=params['guidance_interval_decay'],\n",
    "        min_guidance_scale=params['min_guidance_scale'],\n",
    "        use_erg_tag=params['use_erg_tag'],\n",
    "        use_erg_lyric=params['use_erg_lyric'],\n",
    "        use_erg_diffusion=params['use_erg_diffusion'],\n",
    "        omega_scale=params['omega_scale'],\n",
    "        audio2audio_enable = params['audio2audio_enable'],\n",
    "        ref_audio_strength = params['ref_audio_strength'],\n",
    "        ref_audio_input = params['ref_audio_input'],\n",
    "        save_path = params['audio_outputs_path']\n",
    "    )\n",
    "        \n",
    "    return output_paths, input_params_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e27d2cd-9e8e-4b6a-a69f-81881475cdac",
   "metadata": {},
   "source": [
    "### Initialize the results dataframe to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eccbe7-f0b0-4129-8f92-2f1215f9115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DATAFRAME_COLUMNS = [\n",
    "    'format',\n",
    "    'lora_name_or_path',\n",
    "    'lora_weight',\n",
    "    'task',\n",
    "    'prompt',\n",
    "    'lyrics',\n",
    "    'audio_duration',\n",
    "    'infer_step',\n",
    "    'guidance_scale',\n",
    "    'scheduler_type',\n",
    "    'cfg_type',\n",
    "    'omega_scale',\n",
    "    'guidance_interval',\n",
    "    'guidance_interval_decay',\n",
    "    'min_guidance_scale',\n",
    "    'use_erg_tag',\n",
    "    'use_erg_lyric',\n",
    "    'use_erg_diffusion',\n",
    "    'oss_steps',\n",
    "    'timecosts',\n",
    "    'manual_seeds',\n",
    "    'actual_seeds',\n",
    "    'retake_seeds',\n",
    "    'retake_variance',\n",
    "    'guidance_scale_text',\n",
    "    'guidance_scale_lyric',\n",
    "    'repaint_start',\n",
    "    'repaint_end',\n",
    "    'edit_n_min',\n",
    "    'edit_n_max',\n",
    "    'edit_n_avg',\n",
    "    'src_audio_path',\n",
    "    'edit_target_prompt',\n",
    "    'edit_target_lyrics',\n",
    "    'audio2audio_enable',\n",
    "    'ref_audio_strength',\n",
    "    'ref_audio_input',\n",
    "    'audio_path',\n",
    "    'use_erg',\n",
    "    'complete',\n",
    "    'compute_duration'\n",
    "]\n",
    "\n",
    "pd.DataFrame(data=[], columns=OUTPUT_DATAFRAME_COLUMNS).to_csv(\n",
    "    grid_search_output_dataframe_filepath,\n",
    "    mode='w', header=True, index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a33a31-3074-4d7a-babd-16e3346cc183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(OUTPUT_DATAFRAME_COLUMNS).difference(set(all_params.keys()))\n",
    "# all_param"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ffc03b-2c1e-41d4-b0b5-82a494b46c97",
   "metadata": {},
   "source": [
    "# Run Grid Search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48ab21-690f-4e9e-b262-9ec11f2b2d67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_runs = grid_dataframe.shape[0]\n",
    "for _n_runs, (_index, _row) in enumerate(grid_dataframe.iterrows()):\n",
    "    print(f'Running inference {_n_runs} of {total_runs}...')\n",
    "    input_params = _row.to_dict()\n",
    "\n",
    "    if input_params.get('ref_audio_input') is not None:\n",
    "        input_params['audio_duration'] = librosa.get_duration(path=input_params.get('ref_audio_input'))\n",
    "        input_params['audio2audio_enable'] = True\n",
    "    else:\n",
    "        input_params['audio2audio_enable'] = False\n",
    "        input_params['audio_duration'] = AUDIO_DURATION\n",
    "        \n",
    "    input_params['use_erg_tag'] = input_params.get('use_erg')\n",
    "    input_params['use_erg_lyric'] = input_params.get('use_erg')\n",
    "    input_params['use_erg_diffusion'] = input_params.get('use_erg')\n",
    "\n",
    "    \n",
    "    # Generate song\n",
    "    t0 = time.process_time()\n",
    "    output_path, input_params_json = generate_song(params=input_params)\n",
    "    \n",
    "    # update all_params\n",
    "    all_params = merge_params(\n",
    "        target=input_params,\n",
    "        recorded=input_params_json\n",
    "    )\n",
    "    t1 = time.process_time()\n",
    "    generation_time = t1-t0\n",
    "    all_params['compute_duration'] = generation_time\n",
    "    new_output_row_df = pd.json_normalize(all_params, max_level=0)\n",
    "    new_output_row_df = new_output_row_df[OUTPUT_DATAFRAME_COLUMNS]\n",
    "    new_output_row_df.to_csv(\n",
    "        grid_search_output_dataframe_filepath,\n",
    "        mode='a', header=False, index=False\n",
    "    )\n",
    "\n",
    "    # update input params if needing to restart later\n",
    "    grid_dataframe.at[_index, 'complete'] = True\n",
    "    grid_dataframe.to_csv(\n",
    "        path_or_buf=grid_search_input_dataframe_filepath,\n",
    "        mode='w', header=True, index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d5e6e-927d-40c8-8580-74e875951391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7eb63e-eeff-4aa4-8b0a-b41ab1454dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58754e61-d134-4b30-befa-71655eae94f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_df = pd.read_csv(\n",
    "    grid_search_output_dataframe_filepath\n",
    ")\n",
    "completed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b05d30-9a15-4d03-91c5-bbd24df1480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Audio(completed_df.iloc[0]['ref_audio_input']))\n",
    "# for _audio_path in completed_df['audio_path']:\n",
    "#     display(Audio(_audio_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd0dcc7-136b-4d2e-9f42-40f03b2b5d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b21db-23c8-47fe-9330-1dbf4dbeb110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e81d4-4cdc-4cca-9867-519a01affa3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5499c98-c530-4c67-9077-06048ca5e55d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d94131-1194-4f6a-810b-69cea454843f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be19c5-bcc4-4126-a3f1-f92da884e487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da45c2ff-ad4d-44ca-a83d-dd9d561b7bb6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Misc / Abandoned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ed4690-579a-4757-96b9-555abb087289",
   "metadata": {},
   "source": [
    "###### If running from command line to use gradio demo:\n",
    "```\n",
    "acestep \\\n",
    "python gui.py \\\n",
    "--torch_compile true \\\n",
    "--overlapped_decode true \\\n",
    "--lora_dir ./models/exp/ace_step_lora_rjwpersonal/ \\\n",
    "--port 7866\n",
    "\n",
    "acestep \\\n",
    "--torch_compile true \\\n",
    "--cpu_offload true \\\n",
    "--overlapped_decode true \\\n",
    "--port 7866\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b60785-ff33-4cf2-a7b8-16eb5f4dbdab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ace_step",
   "language": "python",
   "name": "ace_step"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
