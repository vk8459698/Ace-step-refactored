{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb400e-24dc-4ba3-b01d-8a3757f128c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f6e4b24-cc31-4248-83da-b9b4aea782f6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d08682f1-6543-4f4f-af19-5a138df1ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import hdf5plugin\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a25db97a-ea4e-4718-bee9-b5767c340680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_bf16_supported()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "946275ad-4692-4a42-952c-9181c06e4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/mnt/disks/audio-ai-research-speech-data/ace_step_datasets/rjw_all_LoRa_data/processed/\"\n",
    "file_path = '/mnt/disks/audio-ai-research-speech-data/ace_step_datasets/rjw_all_LoRa_data/processed/MERIDIAN_BTBC_MASTER_2024_08_07_00_24b__000.hdf5'\n",
    "# f = h5py.File(file_path, 'r')  # 'r' for read-only mode\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6671f0f8-ebd2-44d6-bc8f-44ec547b9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     k: torch.from_numpy(np.asarray(f[k])) for k in f.keys() if k != \"keys\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b57fc57-1328-4c47-8487-6ce0ea60e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_structure(item, level=0):\n",
    "    if isinstance(item, h5py.Group):\n",
    "        print('  ' * level + f\"Group: {item.name}\")\n",
    "        for key in item.keys():\n",
    "            print_structure(item[key], level + 1)\n",
    "    elif isinstance(item, h5py.Dataset):\n",
    "        print('  ' * level + f\"Dataset: {item.name}, Shape: {item.shape}, Type: {item.dtype}\")\n",
    "\n",
    "# print_structure(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d47551-32ab-4594-9631-11b54cff3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f['lyric_mask']#[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c0ee99a-08d0-4e4c-80be-ccf8b5d05cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_tags(text_token_ids, mask, shuffle, dropout):\n",
    "    if not shuffle and not dropout:\n",
    "        return text_token_ids, mask\n",
    "\n",
    "    COMMA = 275\n",
    "    bos = text_token_ids[-1:]\n",
    "    text_token_ids = text_token_ids[:-1]\n",
    "\n",
    "    tags = []\n",
    "    start_idx = 0\n",
    "    _len = len(text_token_ids)\n",
    "    for idx in range(_len):\n",
    "        if text_token_ids[idx] == COMMA:\n",
    "            if start_idx < idx:\n",
    "                tags.append(text_token_ids[start_idx:idx])\n",
    "            start_idx = idx + 1\n",
    "    if start_idx < _len:\n",
    "        tags.append(text_token_ids[start_idx:_len])\n",
    "\n",
    "    if shuffle:\n",
    "        # Shuffle tags using torch's random seed\n",
    "        perm = torch.randperm(len(tags))\n",
    "        tags = [tags[i] for i in perm]\n",
    "\n",
    "    if dropout:\n",
    "        tags = [x for x in tags if torch.rand(()) > dropout]\n",
    "\n",
    "    comma = torch.tensor([COMMA], dtype=text_token_ids.dtype)\n",
    "    tags_and_commas = []\n",
    "    for x in tags:\n",
    "        tags_and_commas.append(x)\n",
    "        tags_and_commas.append(comma)\n",
    "    if tags_and_commas:\n",
    "        tags_and_commas[-1] = bos\n",
    "    else:\n",
    "        tags_and_commas.append(bos)\n",
    "\n",
    "    text_token_ids = torch.cat(tags_and_commas)\n",
    "    mask = mask[: len(text_token_ids)]\n",
    "    return text_token_ids, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b55266e-8caa-43f1-8deb-af0d95056382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytree_to_dtype(x, dtype):\n",
    "    if isinstance(x, list):\n",
    "        return [pytree_to_dtype(y, dtype) for y in x]\n",
    "    elif isinstance(x, dict):\n",
    "        return {k: pytree_to_dtype(v, dtype) for k, v in x.items()}\n",
    "    elif isinstance(x, torch.Tensor) and x.dtype.is_floating_point:\n",
    "        return x.to(dtype)\n",
    "    else:\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0b1e869-745a-4c0d-9e64-5e81fb0b7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDF5Dataset(Dataset):\n",
    "\tdef __init__(self, dataset_path, dtype, tag_shuffle, tag_dropout):\n",
    "\t\tself.dataset_path = dataset_path\n",
    "\t\tself.dtype = dtype\n",
    "\t\tself.tag_shuffle = tag_shuffle\n",
    "\t\tself.tag_dropout = tag_dropout\n",
    "\t\tself.filenames = sorted(os.listdir(dataset_path))\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.filenames)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tfile_path = os.path.join(self.dataset_path, self.filenames[idx])\n",
    "\t\twith h5py.File(file_path, \"r\") as f:\n",
    "\t\t\t# torch.tensor(f[k]) is slow\n",
    "\t\t\tsample = {\n",
    "\t\t\t\tk: torch.from_numpy(np.asarray(f[k])) for k in f.keys() if k != \"keys\"\n",
    "\t\t\t}\n",
    "\t\tsample[\"text_token_ids\"], sample[\"text_attention_mask\"] = augment_tags(\n",
    "\t\t\tsample[\"text_token_ids\"],\n",
    "\t\t\tsample[\"text_attention_mask\"],\n",
    "\t\t\tself.tag_shuffle,\n",
    "\t\t\tself.tag_dropout,\n",
    "\t\t)\n",
    "\t\tsample[\"text_attention_mask\"] = sample[\"text_attention_mask\"].float()\n",
    "\t\tsample = pytree_to_dtype(sample, self.dtype)\n",
    "\t\treturn sample\n",
    "\n",
    "if torch.cuda.is_bf16_supported():\n",
    "\tto_dtype = torch.bfloat16\n",
    "else:\n",
    "\tto_dtype = torch.float16\n",
    "\n",
    "tag_dropout = 0.5\n",
    "\n",
    "ds = HDF5Dataset(\n",
    "\tdataset_path=dataset_path,\n",
    "\tdtype=to_dtype,\n",
    "\ttag_shuffle=True,\n",
    "\ttag_dropout=tag_dropout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77cf57a3-adf2-4f3e-a2f8-a7f2cf91af27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUGER_Armchair_Cartographer_MASTER_2023_05_19_00_24b__000.hdf5\n"
     ]
    }
   ],
   "source": [
    "TEST_INDEX=0\n",
    "print(ds.filenames[TEST_INDEX])\n",
    "one_item = ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b84c996-ae77-4721-be83-c98df2955078",
   "metadata": {},
   "outputs": [],
   "source": [
    "look for \"prompts? not tags?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3151cc4d-fd9d-4e7b-a4fb-e2c041a81562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ===== ===== ===== ===== ===== #\n",
      "Key: attention_mask\n",
      "torch.Size([323]) tensor(1., dtype=torch.bfloat16)\n",
      "# ===== ===== ===== ===== ===== #\n",
      "# ===== ===== ===== ===== ===== #\n",
      "Key: lyric_mask\n",
      "torch.Size([4]) tensor(1., dtype=torch.bfloat16)\n",
      "# ===== ===== ===== ===== ===== #\n",
      "# ===== ===== ===== ===== ===== #\n",
      "Key: lyric_token_ids\n",
      "tensor([ 261,  259, 6688,    2])\n",
      "# ===== ===== ===== ===== ===== #\n",
      "# ===== ===== ===== ===== ===== #\n",
      "Key: mert_ssl_hidden_states\n",
      "torch.Size([2244, 1024]) tensor(0.0071, dtype=torch.bfloat16)\n",
      "# ===== ===== ===== ===== ===== #\n",
      "# ===== ===== ===== ===== ===== #\n",
      "Key: mhubert_ssl_hidden_states\n",
      "torch.Size([1499, 768]) tensor(-0.0031, dtype=torch.bfloat16)\n",
      "# ===== ===== ===== ===== ===== #\n",
      "# ===== ===== ===== ===== ===== #\n",
      "Key: speaker_embds\n",
      "torch.Size([512]) tensor(0., dtype=torch.bfloat16)\n",
      "# ===== ===== ===== ===== ===== #\n",
      "# ===== ===== ===== ===== ===== #\n",
      "Key: target_latents\n",
      "torch.Size([8, 16, 323]) tensor(0.2236, dtype=torch.bfloat16)\n",
      "# ===== ===== ===== ===== ===== #\n",
      "# ===== ===== ===== ===== ===== #\n",
      "Key: text_attention_mask\n",
      "torch.Size([23]) tensor(1., dtype=torch.bfloat16)\n",
      "# ===== ===== ===== ===== ===== #\n",
      "# ===== ===== ===== ===== ===== #\n",
      "Key: text_token_ids\n",
      "tensor([163642,  28931,    275, 150958,    319,    275,    333,  79159,    275,\n",
      "         79159,    275,   1538,  45853,    275,    273,    277,    277,    278,\n",
      "           274,    284,    748,   7678,      1])\n",
      "# ===== ===== ===== ===== ===== #\n"
     ]
    }
   ],
   "source": [
    "for _key, _item in one_item.items():\n",
    "    print(\"# ===== ===== ===== ===== ===== #\")\n",
    "    print(f'Key: {_key}')\n",
    "    try:\n",
    "        print(_item.shape, _item.mean())\n",
    "    except:\n",
    "        print(_item)\n",
    "    print(\"# ===== ===== ===== ===== ===== #\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16d316a-cdb5-42a5-aad8-a024953e31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dataloader(self):\n",
    "    ds = HDF5Dataset(\n",
    "        dataset_path=self.hparams.dataset_path,\n",
    "        dtype=self.to_dtype,\n",
    "        tag_shuffle=True,\n",
    "        tag_dropout=self.hparams.tag_dropout,\n",
    "    )\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=self.hparams.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=self.hparams.num_workers,\n",
    "        # pin_memory=True,\n",
    "        # persistent_workers=True,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ace_step",
   "language": "python",
   "name": "ace_step"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
